<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>GCP Exam Practice - Part 6 (Questions 251-302)</title>
  <style>
    body { 
      font-family: Arial, sans-serif; 
      margin: 20px; 
      line-height: 1.6;
    }
    
    .question { 
      margin-bottom: 25px; 
      position: relative; 
      border: 1px solid #e0e0e0; 
      border-radius: 8px; 
      padding: 15px; 
      background: #fff;
      box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    
    .answers input { margin-right: 10px; }
    .answers label { 
      display: block; 
      margin-bottom: 8px; 
      padding: 8px;
      border-radius: 4px;
      transition: background-color 0.2s;
    }
    .answers label:hover { background-color: #f5f5f5; }
    
    .submit-btn { margin-top: 20px; }
    strong.keyword { font-weight: bold; color: darkblue; }
    
    .part-info { 
      background-color: #f0f8ff; 
      padding: 15px; 
      border-radius: 8px; 
      margin-bottom: 25px;
      border-left: 4px solid #4285f4;
    }
    
    .question-header { 
      display: flex; 
      justify-content: space-between; 
      align-items: flex-start; 
      margin-bottom: 15px;
      gap: 10px;
    }
    
    .difficult-btn { 
      background: linear-gradient(135deg, #ffd700 0%, #ffed4e 100%); 
      border: none; 
      padding: 8px; 
      border-radius: 50%; 
      cursor: pointer; 
      font-size: 16px; 
      font-weight: bold; 
      color: #333; 
      transition: all 0.3s ease;
      box-shadow: 0 2px 5px rgba(0,0,0,0.1);
      width: 36px;
      height: 36px;
      display: flex;
      align-items: center;
      justify-content: center;
      flex-shrink: 0;
    }
    
    .difficult-btn:hover { 
      transform: translateY(-2px) scale(1.1); 
      box-shadow: 0 4px 10px rgba(0,0,0,0.2); 
    }
    
    .difficult-btn.marked { 
      background: linear-gradient(135deg, #ea4335 0%, #fbbc04 100%); 
      color: white; 
      animation: pulse 0.6s ease-in-out;
    }
    
    @keyframes pulse {
      0% { transform: scale(1); }
      50% { transform: scale(1.2); }
      100% { transform: scale(1); }
    }
    
    .question-content { 
      flex: 1; 
      min-width: 0;
    }
    
    .question-content p {
      margin: 0;
      word-wrap: break-word;
    }
    
    /* Responsive design for mobile */
    @media (max-width: 768px) {
      body { 
        margin: 10px; 
        font-size: 14px;
      }
      
      .question { 
        padding: 12px; 
        margin-bottom: 20px;
      }
      
      .question-header { 
        flex-direction: column; 
        align-items: flex-end;
        gap: 8px;
      }
      
      .difficult-btn { 
        width: 32px; 
        height: 32px; 
        font-size: 14px;
        padding: 6px;
      }
      
      .part-info { 
        padding: 12px; 
        margin-bottom: 20px;
      }
      
      .answers label { 
        padding: 6px; 
        margin-bottom: 6px;
        font-size: 13px;
      }
    }
    
    @media (max-width: 480px) {
      body { 
        margin: 8px; 
        font-size: 13px;
      }
      
      .question { 
        padding: 10px; 
        margin-bottom: 15px;
      }
      
      .difficult-btn { 
        width: 28px; 
        height: 28px; 
        font-size: 12px;
        padding: 5px;
      }
      
      .part-info { 
        padding: 10px; 
        margin-bottom: 15px;
      }
      
      .answers label { 
        padding: 5px; 
        margin-bottom: 5px;
        font-size: 12px;
      }
    }
  </style>
</head>
<body>
<div class="part-info">
  <h1>GCP Exam Practice - Part 6</h1>
  <p><strong>Questions 251-302 of 302</strong></p>
  <p>This is part 6 of 6 quiz sections. Each question will show immediate feedback when you select an answer.</p>
  <div style="margin-top: 15px;">
    <a href="index.html" style="display: inline-block; background: #4285f4; color: white; text-decoration: none; padding: 10px 20px; border-radius: 20px; font-weight: 500;">üè† V·ªÅ trang ch·ªß</a>
  </div>
</div>
<form id="quizForm">
<div class="question">
<p><strong>Question 251:</strong> <strong class="keyword"></strong>

You installed the Google Cloud CLI on your workstation and set the proxy configuration. However, you are worried that your proxy credentials will be recorded in the gcloud CLI logs. You want to prevent your proxy credential from being logged. What should you do?</p>
<div class="answers">
<label><input name="q1" type="radio" value="A"/> A. Configure username and password by using gcloud config set proxy/username and gcloud config set proxy/password commands.</label><br/>
<label><input name="q1" type="radio" value="B"/> B. Encode username and password in sha256 encoding, and save in to a text file. Use filename as a value in the gcloud config set core/custom_ca_certs_file command.</label><br/>
<label><input name="q1" type="radio" value="C"/> C. Provide values for CLOUDSDK_PROXY_USERNAME and CLOUDSDK_PROXY_PASSWORD in the gcloud CLI tool configuration file.</label><br/>
<label><input name="q1" type="radio" value="D"/> D. Set the CLOUDSDK_PROXY_USERNAME and CLOUDSDK_PROXY_PASSWORD properties by using environment variables in your command line tool.</label>
</div>
</div>
<div class="question">
<p><strong>Question 252:</strong> <strong class="keyword"></strong>

Your company developed an application to deploy on Google Kubernetes Engine. Certain parts of the application are not fault-tolerant and are allowed to have downtime. Other parts of the application are critical and must always be available. You need to configure a Google Kubernetes Engine cluster while optimizing for cost. What should you do?</p>
<div class="answers">
<label><input name="q2" type="radio" value="A"/> A. Create a cluster with a single node-pool by using standard VMs. Label he fault-tolerant Deployments as spot_true.</label><br/>
<label><input name="q2" type="radio" value="B"/> B. Create a cluster with a single node-pool by using Spot VMs. Label the critical Deployments as spot_false.</label><br/>
<label><input name="q2" type="radio" value="C"/> C. Create a cluster with both a Spot VM node pool and a node pool by using standard VMs. Deploy the critical deployments on the Spot VM node pool and the fault-tolerant deployments on the node pool by using standard VMs.</label><br/>
<label><input name="q2" type="radio" value="D"/> D. Create a cluster with both a Spot VM node pool and a nods pool by using standard VMs. Deploy the critical deployments on the node pool by using standard VMs and the fault-tolerant deployments on the Spot VM node pool.</label>
</div>
</div>
<div class="question">
<p><strong>Question 253:</strong> <strong class="keyword"></strong>

You need to deploy an application in Google Cloud using serverless technology. You want to test a new version of the application with a small percentage of production traffic. What should you do?</p>
<div class="answers">
<label><input name="q3" type="radio" value="A"/> A. Deploy the application to Cloud Run. Use gradual rollouts for traffic splitting.</label><br/>
<label><input name="q3" type="radio" value="B"/> B. Deploy the application to Google Kubernetes Engine. Use Anthos Service Mash for traffic splitting.</label><br/>
<label><input name="q3" type="radio" value="C"/> C. Deploy the application to Cloud Functions. Specify the version number in the functions name.</label><br/>
<label><input name="q3" type="radio" value="D"/> D. Deploy the application to App Engine. For each new version, create a new service.</label>
</div>
</div>
<div class="question">
<p><strong>Question 254:</strong> <strong class="keyword"></strong>

Your company's security vulnerability management policy wants a member of the security team to have visibility into vulnerabilities and other OS metadata for a specific Compute Engine instance. This Compute Engine instance hosts a critical application in your Google Cloud project. You need to implement your company's security vulnerability management policy. What should you do?</p>
<div class="answers">
<label><input name="q4" type="radio" value="A"/> A. ‚Ä¢ Ensure that the Ops Agent is installed on the Compute Engine instance.‚Ä¢ Create a custom metric in the Cloud Monitoring dashboard.‚Ä¢ Provide the security team member with access to this dashboard.</label><br/>
<label><input name="q4" type="radio" value="B"/> B. ‚Ä¢ Ensure that the Ops Agent is installed on the Compute Engine instance.‚Ä¢ Provide the security team member roles/osconfig.inventoryViewer permission.</label><br/>
<label><input name="q4" type="radio" value="C"/> C. ‚Ä¢ Ensure that the OS Config agent is installed on the Compute Engine instance.‚Ä¢ Provide the security team member roles/osconfig.vulnerabilityReportViewer permission.</label><br/>
<label><input name="q4" type="radio" value="D"/> D. ‚Ä¢ Ensure that the OS Config agent is installed on the Compute Engine instance.‚Ä¢ Create a log sink to BigQuery dataset.‚Ä¢ Provide the security team member with access to this dataset.</label>
</div>
</div>
<div class="question">
<p><strong>Question 255:</strong> <strong class="keyword"></strong>

You want to enable your development team to deploy new features to an existing Cloud Run service in production. To minimize the risk associated with a new revision, you want to reduce the number of customers who might be affected by an outage without introducing any development or operational costs to your customers. You want to follow Google-recommended practices for managing revisions to a service. What should you do?</p>
<div class="answers">
<label><input name="q5" type="radio" value="A"/> A. Ask your customers to retry access to your service with exponential backoff to mitigate any potential problems after the new revision is deployed.</label><br/>
<label><input name="q5" type="radio" value="B"/> B. Gradually roll out the new revision and split customer traffic between the revisions to allow rollback in case a problem occurs.</label><br/>
<label><input name="q5" type="radio" value="C"/> C. Send all customer traffic to the new revision, and roll back to a previous revision if you witness any problems in production.</label><br/>
<label><input name="q5" type="radio" value="D"/> D. Deploy your application to a second Cloud Run service, and ask your customers to use the second Cloud Run service.</label>
</div>
</div>
<div class="question">
<p><strong>Question 256:</strong> <strong class="keyword"></strong>

You have deployed an application on a Compute Engine instance. An external consultant needs to access the Linux-based instance. The consultant is connected to your corporate network through a VPN connection, but the consultant has no Google account. What should you do?</p>
<div class="answers">
<label><input name="q6" type="radio" value="A"/> A. Instruct the external consultant to use the gcloud compute ssh command line tool by using Identity-Aware Proxy to access the instance.</label><br/>
<label><input name="q6" type="radio" value="B"/> B. Instruct the external consultant to use the gcloud compute ssh command line tool by using the public IP address of the instance to access it.</label><br/>
<label><input name="q6" type="radio" value="C"/> C. Instruct the external consultant to generate an SSH key pair, and request the public key from the consultant. Add the public key to the instance yourself, and have the consultant access the instance through SSH with their private key.</label><br/>
<label><input name="q6" type="radio" value="D"/> D. Instruct the external consultant to generate an SSH key pair, and request the private key from the consultant. Add the private key to the instance yourself, and have the consultant access the instance through SSH with their public key.</label>
</div>
</div>
<div class="question">
<p><strong>Question 257:</strong> <strong class="keyword"></strong>

After a recent security incident, your startup company wants better insight into what is happening in the Google Cloud environment. You need to monitor unexpected firewall changes and instance creation. Your company prefers simple solutions. What should you do?</p>
<div class="answers">
<label><input name="q7" type="radio" value="A"/> A. Create a log sink to forward Cloud Audit Logs filtered for firewalls and compute instances to Cloud Storage. Use BigQuery to periodically analyze log events in the storage bucket.</label><br/>
<label><input name="q7" type="radio" value="B"/> B. Use Cloud Logging filters to create log-based metrics for firewall and instance actions. Monitor the changes and set up reasonable alerts.</label><br/>
<label><input name="q7" type="radio" value="C"/> C. Install Kibana on a compute instance. Create a log sink to forward Cloud Audit Logs filtered for firewalls and compute instances to Pub/Sub. Target the Pub/Sub topic to push messages to the Kibana instance. Analyze the logs on Kibana in real time.</label><br/>
<label><input name="q7" type="radio" value="D"/> D. Turn on Google Cloud firewall rules logging, and set up alerts for any insert, update, or delete events.</label>
</div>
</div>
<div class="question">
<p><strong>Question 258:</strong> <strong class="keyword"></strong>

You are configuring service accounts for an application that spans multiple projects. Virtual machines (VMs) running in the web-applications project need access to BigQuery datasets in the crm-databases project. You want to follow Google-recommended practices to grant access to the service account in the web-applications project. What should you do?</p>
<div class="answers">
<label><input name="q8" type="radio" value="A"/> A. Grant "project owner" for web-applications appropriate roles to crm-databases.</label><br/>
<label><input name="q8" type="radio" value="B"/> B. Grant "project owner" role to crm-databases and the web-applications project.</label><br/>
<label><input name="q8" type="radio" value="C"/> C. Grant "project owner" role to crm-databases and roles/bigquery.dataViewer role to web-applications.</label><br/>
<label><input name="q8" type="radio" value="D"/> D. Grant roles/bigquery.dataViewer role to crm-databases and appropriate roles to web-applications.</label>
</div>
</div>
<div class="question">
<p><strong>Question 259:</strong> <strong class="keyword"></strong>

Your Dataproc cluster runs in a single Virtual Private Cloud (VPC) network in a single subnetwork with range 172.16.20.128/25. There are no private IP addresses available in the subnetwork. You want to add new VMs to communicate with your cluster using the minimum number of steps. What should you do?</p>
<div class="answers">
<label><input name="q9" type="radio" value="A"/> A. Modify the existing subnet range to 172.16.20.0/24.</label><br/>
<label><input name="q9" type="radio" value="B"/> B. Create a new Secondary IP Range in the VPC and configure the VMs to use that range.</label><br/>
<label><input name="q9" type="radio" value="C"/> C. Create a new VPC network for the VMs. Enable VPC Peering between the VMs'VPC network and the Dataproc cluster VPC network.</label><br/>
<label><input name="q9" type="radio" value="D"/> D. Create a new VPC network for the VMs with a subnet of 172.32.0.0/16. Enable VPC network Peering between the Dataproc VPC network and the VMs VPC network. Configure a custom Route exchange.</label>
</div>
</div>
<div class="question">
<p><strong>Question 260:</strong> <strong class="keyword"></strong>

You are building a backend service for an ecommerce platform that will persist transaction data from mobile and web clients. After the platform is launched, you expect a large volume of global transactions. Your business team wants to run SQL queries to analyze the data. You need to build a highly available and scalable data store for the platform. What should you do?</p>
<div class="answers">
<label><input name="q10" type="radio" value="A"/> A. Create a multi-region Cloud Spanner instance with an optimized schema.</label><br/>
<label><input name="q10" type="radio" value="B"/> B. Create a multi-region Firestore database with aggregation query enabled.</label><br/>
<label><input name="q10" type="radio" value="C"/> C. Create a multi-region Cloud SQL for PostgreSQL database with optimized indexes.</label><br/>
<label><input name="q10" type="radio" value="D"/> D. Create a multi-region BigQuery dataset with optimized tables.</label>
</div>
</div>
<div class="question">
<p><strong>Question 261:</strong> <strong class="keyword"></strong>

You are in charge of provisioning access for all Google Cloud users in your organization. Your company recently acquired a startup company that has their own Google Cloud organization. You need to ensure that your Site Reliability Engineers (SREs) have the same project permissions in the startup company's organization as in your own organization. What should you do?</p>
<div class="answers">
<label><input name="q11" type="radio" value="A"/> A. In the Google Cloud console for your organization, select Create role from selection, and choose destination as the startup company's organization.</label><br/>
<label><input name="q11" type="radio" value="B"/> B. In the Google Cloud console for the startup company, select Create role from selection and choose source as the startup company's Google Cloud organization.</label><br/>
<label><input name="q11" type="radio" value="C"/> C. Use the gcloud iam roles copy command, and provide the Organization ID of the startup company's Google Cloud Organization as the destination.</label><br/>
<label><input name="q11" type="radio" value="D"/> D. Use the gcloud iam roles copy command, and provide the project IDs of all projects in the startup company's organization as the destination.</label>
</div>
</div>
<div class="question">
<p><strong>Question 262:</strong> <strong class="keyword"></strong>

You need to extract text from audio files by using the Speech-to-Text API. The audio files are pushed to a Cloud Storage bucket. You need to implement a fully managed, serverless compute solution that requires authentication and aligns with Google-recommended practices. You want to automate the call to the API by submitting each file to the API as the audio file arrives in the bucket. What should you do?</p>
<div class="answers">
<label><input name="q12" type="radio" value="A"/> A. Create an App Engine standard environment triggered by Cloud Storage bucket events to submit the file URI to the Google Speech-to-TextAPI.</label><br/>
<label><input name="q12" type="radio" value="B"/> B. Run a Kubernetes job to scan the bucket regularly for incoming files, and call the Speech-to-Text API for each unprocessed file.</label><br/>
<label><input name="q12" type="radio" value="C"/> C. Run a Python script by using a Linux cron job in Compute Engine to scan the bucket regularly for incoming files, and call the Speech-to-Text API for each unprocessed file.</label><br/>
<label><input name="q12" type="radio" value="D"/> D. Create a Cloud Function triggered by Cloud Storage bucket events to submit the file URI to the Google Speech-to-Text API.</label>
</div>
</div>
<div class="question">
<p><strong>Question 263:</strong> <strong class="keyword"></strong>

Your customer wants you to create a secure website with autoscaling based on the compute instance CPU load. You want to enhance performance by storing static content in Cloud Storage. Which resources are needed to distribute the user traffic?</p>
<div class="answers">
<label><input name="q13" type="radio" value="A"/> A. An external HTTP(S) load balancer with a managed SSL certificate to distribute the load and a URL map to target the requests for the static content to the Cloud Storage backend.</label><br/>
<label><input name="q13" type="radio" value="B"/> B. An external network load balancer pointing to the backend instances to distribute the load evenly. The web servers will forward the request to the Cloud Storage as needed.</label><br/>
<label><input name="q13" type="radio" value="C"/> C. An internal HTTP(S) load balancer together with Identity-Aware Proxy to allow only HTTPS traffic.</label><br/>
<label><input name="q13" type="radio" value="D"/> D. An external HTTP(S) load balancer to distribute the load and a URL map to target the requests for the static content to the Cloud Storage backend. Install the HTTPS certificates on the instance.</label>
</div>
</div>
<div class="question">
<p><strong>Question 264:</strong> <strong class="keyword"></strong>

The core business of your company is to rent out construction equipment at large scale. All the equipment that is being rented out has been equipped with multiple sensors that send event information every few seconds. These signals can vary from engine status, distance traveled, fuel level, and more. Customers are billed based on the consumption monitored by these sensors. You expect high throughput ‚Äì up to thousands of events per hour per device ‚Äì and need to retrieve consistent data based on the time of the event. Storing and retrieving individual signals should be atomic. What should you do?</p>
<div class="answers">
<label><input name="q14" type="radio" value="A"/> A. Create files in Cloud Storage as data comes in.</label><br/>
<label><input name="q14" type="radio" value="B"/> B. Create a file in Filestore per device, and append new data to that file.</label><br/>
<label><input name="q14" type="radio" value="C"/> C. Ingest the data into Cloud SQL. Use multiple read replicas to match the throughput.</label><br/>
<label><input name="q14" type="radio" value="D"/> D. Ingest the data into Bigtable. Create a row key based on the event timestamp.</label>
</div>
</div>
<div class="question">
<p><strong>Question 265:</strong> <strong class="keyword"></strong>

You just installed the Google Cloud CLI on your new corporate laptop. You need to list the existing instances of your company on Google Cloud. What must you do before you run the gcloud compute instances list command? (Choose two.)</p>
<div class="answers">
<label><input name="q15" type="radio" value="A"/> A. Run gcloud auth login, enter your login credentials in the dialog window, and paste the received login token to gcloud CLI.</label><br/>
<label><input name="q15" type="radio" value="B"/> B. Create a Google Cloud service account, and download the service account key. Place the key file in a folder on your machine where gcloud CLI can find it.</label><br/>
<label><input name="q15" type="radio" value="C"/> C. Download your Cloud Identity user account key. Place the key file in a folder on your machine where gcloud CLI can find it.</label><br/>
<label><input name="q15" type="radio" value="D"/> D. Run gcloud config set compute/zone $my_zone to set the default zone for gcloud CLI.

E. Run gcloud config set project $my_project to set the default project for gcloud CLI.</label>
</div>
</div>
<div class="question">
<p><strong>Question 266:</strong> <strong class="keyword"></strong>

You are planning to migrate your on-premises data to Google Cloud. The data includes:‚Ä¢ 200 TB of video files in SAN storage‚Ä¢ Data warehouse data stored on Amazon Redshift‚Ä¢ 20 GB of PNG files stored on an S3 bucketYou need to load the video files into a Cloud Storage bucket, transfer the data warehouse data into BigQuery, and load the PNG files into a second Cloud Storage bucket. You want to follow Google-recommended practices and avoid writing any code for the migration. What should you do?</p>
<div class="answers">
<label><input name="q16" type="radio" value="A"/> A. Use gcloud storage for the video files, Dataflow for the data warehouse data, and Storage Transfer Service for the PNG files.</label><br/>
<label><input name="q16" type="radio" value="B"/> B. Use Transfer Appliance for the videos, BigQuery Data Transfer Service for the data warehouse data, and Storage Transfer Service for the PNG files.</label><br/>
<label><input name="q16" type="radio" value="C"/> C. Use Storage Transfer Service for the video files, BigQuery Data Transfer Service for the data warehouse data, and Storage Transfer Service for the PNG files.</label><br/>
<label><input name="q16" type="radio" value="D"/> D. Use Cloud Data Fusion for the video files, Dataflow for the data warehouse data, and Storage Transfer Service for the PNG files.</label>
</div>
</div>
<div class="question">
<p><strong>Question 267:</strong> <strong class="keyword"></strong>

You want to deploy a new containerized application into Google Cloud by using a Kubernetes manifest. You want to have full control over the Kubernetes deployment, and at the same time, you want to minimize configuring infrastructure. What should you do?</p>
<div class="answers">
<label><input name="q17" type="radio" value="A"/> A. Deploy the application on GKE Autopilot.</label><br/>
<label><input name="q17" type="radio" value="B"/> B. Deploy the application on Cloud Run.</label><br/>
<label><input name="q17" type="radio" value="C"/> C. Deploy the application on GKE Standard.</label><br/>
<label><input name="q17" type="radio" value="D"/> D. Deploy the application on Cloud Functions.</label>
</div>
</div>
<div class="question">
<p><strong>Question 268:</strong> <strong class="keyword"></strong>

Your team is building a website that handles votes from a large user population. The incoming votes will arrive at various rates. You want to optimize the storage and processing of the votes. What should you do?</p>
<div class="answers">
<label><input name="q18" type="radio" value="A"/> A. Save the incoming votes to Firestore. Use Cloud Scheduler to trigger a Cloud Functions instance to periodically process the votes.</label><br/>
<label><input name="q18" type="radio" value="B"/> B. Use a dedicated instance to process the incoming votes. Send the votes directly to this instance.</label><br/>
<label><input name="q18" type="radio" value="C"/> C. Save the incoming votes to a JSON file on Cloud Storage. Process the votes in a batch at the end of the day.</label><br/>
<label><input name="q18" type="radio" value="D"/> D. Save the incoming votes to Pub/Sub. Use the Pub/Sub topic to trigger a Cloud Functions instance to process the votes.</label>
</div>
</div>
<div class="question">
<p><strong>Question 269:</strong> <strong class="keyword"></strong>

You are deploying an application on Google Cloud that requires a relational database for storage. To satisfy your company‚Äôs security policies, your application must connect to your database through an encrypted and authenticated connection that requires minimal management and integrates with Identity and Access Management (IAM). What should you do?</p>
<div class="answers">
<label><input name="q19" type="radio" value="A"/> A. Deploy a Cloud SQL database with the SSL mode set to encrypted only, configure SSL/TLS client certificates, and configure a database user and password.</label><br/>
<label><input name="q19" type="radio" value="B"/> B. Deploy a Cloud SQL database with the SSL mode set to encrypted only, configure SSL/TLS client certificates, and configure IAM database authentication.</label><br/>
<label><input name="q19" type="radio" value="C"/> C. Deploy a Cloud SQL database and configure IAM database authentication. Access the database through the Cloud SQL Auth Proxy.</label><br/>
<label><input name="q19" type="radio" value="D"/> D. Deploy a Cloud SQL database and configure a database user and password. Access the database through the Cloud SQL Auth Proxy.</label>
</div>
</div>
<div class="question">
<p><strong>Question 270:</strong> <strong class="keyword"></strong>

You have two Google Cloud projects: project-a with VPC vpc-a (10.0.0.0/16) and project-b with VPC vpc-b (10.8.0.0/16). Your frontend application resides in vpc-a and the backend API services are deployed in vpc-b. You need to efficiently and cost-effectively enable communication between these Google Cloud projects. You also want to follow Google-recommended practices. What should you do?</p>
<div class="answers">
<label><input name="q20" type="radio" value="A"/> A. Create an OpenVPN connection between vpc-a and vpc-b.</label><br/>
<label><input name="q20" type="radio" value="B"/> B. Create VPC Network Peering between vpc-a and vpc-b.</label><br/>
<label><input name="q20" type="radio" value="C"/> C. Configure a Cloud Router in vpc-a and another Cloud Router in vpc-b.</label><br/>
<label><input name="q20" type="radio" value="D"/> D. Configure a Cloud Interconnect connection between vpc-a and vpc-b.</label>
</div>
</div>
<div class="question">
<p><strong>Question 271:</strong> <strong class="keyword"></strong>

Your company is running a critical workload on a single Compute Engine VM instance. Your company's disaster recovery policies require you to back up the entire instance‚Äôs disk data every day. The backups must be retained for 7 days. You must configure a backup solution that complies with your company‚Äôs security policies and requires minimal setup and configuration. What should you do?</p>
<div class="answers">
<label><input name="q21" type="radio" value="A"/> A. Configure the instance to use persistent disk asynchronous replication.</label><br/>
<label><input name="q21" type="radio" value="B"/> B. Configure daily scheduled persistent disk snapshots with a retention period of 7 days.</label><br/>
<label><input name="q21" type="radio" value="C"/> C. Configure Cloud Scheduler to trigger a Cloud Function each day that creates a new machine image and deletes machine images that are older than 7 days.</label><br/>
<label><input name="q21" type="radio" value="D"/> D. Configure a bash script using gsutil to run daily through a cron job. Copy the disk‚Äôs files to a Cloud Storage bucket with archive storage class and an object lifecycle rule to delete the objects after 7 days.</label>
</div>
</div>
<div class="question">
<p><strong>Question 272:</strong> <strong class="keyword"></strong>

Your company requires that Google Cloud products are created with a specific configuration to comply with your company‚Äôs security policies. You need to implement a mechanism that will allow software engineers at your company to deploy and update Google Cloud products in a preconfigured and approved manner. What should you do?</p>
<div class="answers">
<label><input name="q22" type="radio" value="A"/> A. Create Java packages that utilize the Google Cloud Client Libraries for Java to configure Google Cloud products. Store and share the packages in a source code repository.</label><br/>
<label><input name="q22" type="radio" value="B"/> B. Create bash scripts that utilize the Google Cloud CLI to configure Google Cloud products. Store and share the bash scripts in a source code repository.</label><br/>
<label><input name="q22" type="radio" value="C"/> C. Use the Google Cloud APIs by using curl to configure Google Cloud products. Store and share the curl commands in a source code repository.</label><br/>
<label><input name="q22" type="radio" value="D"/> D. Create Terraform modules that utilize the Google Cloud Terraform Provider to configure Google Cloud products. Store and share the modules in a source code repository.</label>
</div>
</div>
<div class="question">
<p><strong>Question 273:</strong> <strong class="keyword"></strong>

You are a Google Cloud organization administrator. You need to configure organization policies and log sinks on Google Cloud projects that cannot be removed by project users to comply with your company's security policies. The security policies are different for each company department. Each company department has a user with the Project Owner role assigned to their projects. What should you do?</p>
<div class="answers">
<label><input name="q23" type="radio" value="A"/> A. Use a standard naming convention for projects that includes the department name. Configure organization policies on the organization and log sinks on the projects.</label><br/>
<label><input name="q23" type="radio" value="B"/> B. Use a standard naming convention for projects that includes the department name. Configure both organization policies and log sinks on the projects.</label><br/>
<label><input name="q23" type="radio" value="C"/> C. Organize projects under folders for each department. Configure both organization policies and log sinks on the folders.</label><br/>
<label><input name="q23" type="radio" value="D"/> D. Organize projects under folders for each department. Configure organization policies on the organization and log sinks on the folders.</label>
</div>
</div>
<div class="question">
<p><strong>Question 274:</strong> <strong class="keyword"></strong>

You are deploying a web application using Compute Engine. You created a managed instance group (MIG) to host the application. You want to follow Google-recommended practices to implement a secure and highly available solution. What should you do?</p>
<div class="answers">
<label><input name="q24" type="radio" value="A"/> A. Use SSL proxy load balancing for the MIG and an A record in your DNS private zone with the load balancer's IP address.</label><br/>
<label><input name="q24" type="radio" value="B"/> B. Use SSL proxy load balancing for the MIG and a CNAME record in your DNS public zone with the load balancer‚Äôs IP address.</label><br/>
<label><input name="q24" type="radio" value="C"/> C. Use HTTP(S) load balancing for the MIG and a CNAME record in your DNS private zone with the load balancer‚Äôs IP address.</label><br/>
<label><input name="q24" type="radio" value="D"/> D. Use HTTP(S) load balancing for the MIG and an A record in your DNS public zone with the load balancer‚Äôs IP address.</label>
</div>
</div>
<div class="question">
<p><strong>Question 275:</strong> <strong class="keyword"></strong>

You have several hundred microservice applications running in a Google Kubernetes Engine (GKE) cluster. Each microservice is a deployment with resource limits configured for each container in the deployment. You've observed that the resource limits for memory and CPU are not appropriately set for many of the microservices. You want to ensure that each microservice has right sized limits for memory and CPU. What should you do?</p>
<div class="answers">
<label><input name="q25" type="radio" value="A"/> A. Configure a Vertical Pod Autoscaler for each microservice.</label><br/>
<label><input name="q25" type="radio" value="B"/> B. Modify the cluster's node pool machine type and choose a machine type with more memory and CPU.</label><br/>
<label><input name="q25" type="radio" value="C"/> C. Configure a Horizontal Pod Autoscaler for each microservice.</label><br/>
<label><input name="q25" type="radio" value="D"/> D. Configure GKE cluster autoscaling.</label>
</div>
</div>
<div class="question">
<p><strong>Question 276:</strong> <strong class="keyword"></strong>

Your company uses BigQuery to store and analyze data. Upon submitting your query in BigQuery, the query fails with a quotaExceeded error. You need to diagnose the issue causing the error. What should you do? (Choose two.)</p>
<div class="answers">
<label><input name="q26" type="radio" value="A"/> A. Use BigQuery BI Engine to analyze the issue.</label><br/>
<label><input name="q26" type="radio" value="B"/> B. Use the INFORMATION_SCHEMA views to analyze the underlying issue.</label><br/>
<label><input name="q26" type="radio" value="C"/> C. Configure Cloud Trace to analyze the issue.</label><br/>
<label><input name="q26" type="radio" value="D"/> D. Search errors in Cloud Audit Logs to analyze the issue.

E. View errors in Cloud Monitoring to analyze the issue.</label>
</div>
</div>
<div class="question">
<p><strong>Question 277:</strong> <strong class="keyword"></strong>

Your team has developed a stateless application which requires it to be run directly on virtual machines. The application is expected to receive a fluctuating amount of traffic and needs to scale automatically. You need to deploy the application. What should you do?</p>
<div class="answers">
<label><input name="q27" type="radio" value="A"/> A. Deploy the application on a managed instance group and configure autoscaling.</label><br/>
<label><input name="q27" type="radio" value="B"/> B. Deploy the application on a Kubernetes Engine cluster and configure node pool autoscaling.</label><br/>
<label><input name="q27" type="radio" value="C"/> C. Deploy the application on Cloud Functions and configure the maximum number instances.</label><br/>
<label><input name="q27" type="radio" value="D"/> D. Deploy the application on Cloud Run and configure autoscaling.</label>
</div>
</div>
<div class="question">
<p><strong>Question 278:</strong> <strong class="keyword"></strong>

Your web application is hosted on Cloud Run and needs to query a Cloud SQL database. Every morning during a traffic spike, you notice API quota errors in Cloud SQL logs. The project has already reached the maximum API quota. You want to make a configuration change to mitigate the issue. What should you do?</p>
<div class="answers">
<label><input name="q28" type="radio" value="A"/> A. Modify the minimum number of Cloud Run instances.</label><br/>
<label><input name="q28" type="radio" value="B"/> B. Use traffic splitting.</label><br/>
<label><input name="q28" type="radio" value="C"/> C. Modify the maximum number of Cloud Run instances.</label><br/>
<label><input name="q28" type="radio" value="D"/> D. Set a minimum concurrent requests environment variable for the application.</label>
</div>
</div>
<div class="question">
<p><strong>Question 279:</strong> <strong class="keyword"></strong>

You need to deploy a single stateless web application with a web interface and multiple endpoints. For security reasons, the web application must be reachable from an internal IP address from your company's private VPC and on-premises network. You also need to update the web application multiple times per day with minimal effort and want to manage a minimal amount of cloud infrastructure. What should you do?</p>
<div class="answers">
<label><input name="q29" type="radio" value="A"/> A. Deploy the web application on Google Kubernetes Engine standard edition with an internal ingress.</label><br/>
<label><input name="q29" type="radio" value="B"/> B. Deploy the web application on Cloud Run with Private Google Access configured.</label><br/>
<label><input name="q29" type="radio" value="C"/> C. Deploy the web application on Cloud Run with Private Service Connect configured.</label><br/>
<label><input name="q29" type="radio" value="D"/> D. Deploy the web application to GKE Autopilot with Private Google Access configured.</label>
</div>
</div>
<div class="question">
<p><strong>Question 280:</strong> <strong class="keyword"></strong>

You use Cloud Logging to capture application logs. You now need to use SQL to analyze the application logs in Cloud Logging, and you want to follow Google-recommended practices. What should you do?</p>
<div class="answers">
<label><input name="q30" type="radio" value="A"/> A. Develop SQL queries by using Gemini for Google Cloud.</label><br/>
<label><input name="q30" type="radio" value="B"/> B. Enable Log Analytics for the log bucket and create a linked dataset in BigQuery.</label><br/>
<label><input name="q30" type="radio" value="C"/> C. Create a schema for the storage bucket and run SQL queries for the data in the bucket.</label><br/>
<label><input name="q30" type="radio" value="D"/> D. Export logs to a storage bucket and create an external view in BigQuery.</label>
</div>
</div>
<div class="question">
<p><strong>Question 281:</strong> <strong class="keyword"></strong>

You need to deploy a third-party software application onto a single Compute Engine VM instance. The application requires the highest speed read and write disk access for the internal database. You need to ensure the instance will recover on failure. What should you do?</p>
<div class="answers">
<label><input name="q31" type="radio" value="A"/> A. Create an instance template. Set the disk type to be an SSD Persistent Disk. Launch the instance template as part of a stateful managed instance group.</label><br/>
<label><input name="q31" type="radio" value="B"/> B. Create an instance template. Set the disk type to be an SSD Persistent Disk. Launch the instance template as part of a stateless managed instance group.</label><br/>
<label><input name="q31" type="radio" value="C"/> C. Create an instance template. Set the disk type to be Hyperdisk Extreme. Launch the instance template as part of a stateful managed instance group.</label><br/>
<label><input name="q31" type="radio" value="D"/> D. Create an instance template. Set the disk type to be Hyperdisk Extreme. Launch the instance template as part of a stateless managed instance group.</label>
</div>
</div>
<div class="question">
<p><strong>Question 282:</strong> <strong class="keyword"></strong>

You have a VM instance running in a VPC with single-stack subnets. You need to ensure that the VM instance has a fixed IP address so that other services hosted in the same VPC can communicate with the VM. You want to follow Google-recommended practices while minimizing cost. What should you do?</p>
<div class="answers">
<label><input name="q32" type="radio" value="A"/> A. Promote the existing IP address of the VM to become a static external IP address.</label><br/>
<label><input name="q32" type="radio" value="B"/> B. Promote the existing IP address of the VM to become a static internal IP address.</label><br/>
<label><input name="q32" type="radio" value="C"/> C. Reserve a new static external IPv6 address and assign the new IP address to the VM.</label><br/>
<label><input name="q32" type="radio" value="D"/> D. Reserve a new static external IP address and assign the new IP address to the VM.</label>
</div>
</div>
<div class="question">
<p><strong>Question 283:</strong> <strong class="keyword"></strong>

Your preview application, deployed on a single-zone Google Kubernetes Engine (GKE) cluster in us-central1, has gained popularity. You are now ready to make the application generally available. You need to deploy the application to production while ensuring high availability and resilience. You also want to follow Google-recommended practices. What should you do?</p>
<div class="answers">
<label><input name="q33" type="radio" value="A"/> A. Use the gcloud container clusters create command with the options --enable-multi-networking and --enable-autoscaling to create an autoscaling zonal cluster and deploy the application to it.</label><br/>
<label><input name="q33" type="radio" value="B"/> B. Use the gcloud container clusters create-auto command to create an autopilot cluster and deploy the application to it.</label><br/>
<label><input name="q33" type="radio" value="C"/> C. Use the gcloud container clusters update command with the option --region us-central1 to update the cluster and deploy the application to it.</label><br/>
<label><input name="q33" type="radio" value="D"/> D. Use the gcloud container clusters update command with the option --node-locations us-central1-a,us-central1-b to update the cluster and deploy the application to the nodes.</label>
</div>
</div>
<div class="question">
<p><strong>Question 284:</strong> <strong class="keyword"></strong>

You are developing an application that will be deployed on Google Cloud. The application will use a service account to retrieve data from BigQuery. Before you deploy your application, you want to test the permissions of this service account from your local machine to ensure there will be no authentication issues. You want to ensure that you use the most secure method while following Google-recommended practices. What should you do?</p>
<div class="answers">
<label><input name="q34" type="radio" value="A"/> A. Generate a service account key, and configure the gcloud CLI to use this key. Issue a relevant BigQuery request through the gdoud CLI to test the access.</label><br/>
<label><input name="q34" type="radio" value="B"/> B. Grant the service account the BigQuery Administrator IAM role to ensure the service account has all required access.</label><br/>
<label><input name="q34" type="radio" value="C"/> C. Configure the gcloud CLI to use service account impersonation. Issue a relevant BigQuery request through the gcloud CLI to test the access.</label><br/>
<label><input name="q34" type="radio" value="D"/> D. Configure the gcloud CLI with Application Default Credentials using your user account. Issue a relevant BigQuery request through the gcloud CLI to test the access.</label>
</div>
</div>
<div class="question">
<p><strong>Question 285:</strong> <strong class="keyword"></strong>

Your organization is migrating to Google Cloud. You want only users with company-issued Google accounts to access your Google Cloud environment. You must ensure that users of the same department can only access resources within their own department. You want to minimize operational costs while following Google-recommended practices. What should you do?</p>
<div class="answers">
<label><input name="q35" type="radio" value="A"/> A. Assign users to the relevant Google Groups, and provide access to cloud resources through Identity and Access Management (IAM) roles. Periodically identify and remove non-company issued Google accounts.</label><br/>
<label><input name="q35" type="radio" value="B"/> B. Assign users to the relevant Google Groups, and provide access to cloud resources through Identity and Access Management (IAM) roles. Use organization policies to block non-company issued emails.</label><br/>
<label><input name="q35" type="radio" value="C"/> C. Create a folder for each department in Resource Manager. Grant the users of each department the Folder Admin role on the folder of their department.</label><br/>
<label><input name="q35" type="radio" value="D"/> D. Create a folder for each department in Resource Manager. Grant all company users the Folder Admin role on the organization level.</label>
</div>
</div>
<div class="question">
<p><strong>Question 286:</strong> <strong class="keyword"></strong>

You are deploying an application to Cloud Run. Your application requires the use of an API that runs on Google Kubernetes Engine (GKE). You need to ensure that your Cloud Run service can privately reach the API on GKE, and you want to follow Google-recommended practices. What should you do?</p>
<div class="answers">
<label><input name="q36" type="radio" value="A"/> A. Deploy an ingress resource on the GKE cluster to expose the API to the internet. Use Cloud Armor to filter for IP addresses that can connect to the API. On the Cloud Run service, configure the application to fetch its public IP address and update the Cloud Armor policy on startup to allow this IP address to call the API on ports 80 and 443.</label><br/>
<label><input name="q36" type="radio" value="B"/> B. Create an ingress firewall rule on the VPC to allow connections from 0.0.0.0/0 on ports 80 and 443.</label><br/>
<label><input name="q36" type="radio" value="C"/> C. Create an egress firewall rule on the VPC to allow connections to 0.0.0.0/ on ports 80 and 443.</label><br/>
<label><input name="q36" type="radio" value="D"/> D. Deploy an internal Application Load Balancer to expose the API on GKE to the VPC. Configure Cloud DNS with the IP address of the internal Application Load Balancer. Deploy a Serverless VPC Access connector to allow the Cloud Run service to call the API through the FQDN on Cloud DNS.</label>
</div>
</div>
<div class="question">
<p><strong>Question 287:</strong> <strong class="keyword"></strong>

Your company uses a multi-cloud strategy that includes Google Cloud. You want to centralize application logs in a third-party software-as-a-service (SaaS) tool from all environments. You need to integrate logs originating from Cloud Logging, and you want to ensure the export occurs with the least amount of delay possible. What should you do?</p>
<div class="answers">
<label><input name="q37" type="radio" value="A"/> A. Create a Cloud Logging sink and configure BigQuery as the destination. Configure the SaaS tool to query BigQuery to retrieve the logs.</label><br/>
<label><input name="q37" type="radio" value="B"/> B. Create a Cloud Logging sink and configure Pub/Sub as the destination. Configure the SaaS tool to subscribe to the Pub/Sub topic to retrieve the logs.</label><br/>
<label><input name="q37" type="radio" value="C"/> C. Create a Cloud Logging sink and configure Cloud Storage as the destination. Configure the SaaS tool to read the Cloud Storage bucket to retrieve the logs.</label><br/>
<label><input name="q37" type="radio" value="D"/> D. Use a Cloud Scheduler cron job to trigger a Cloud Function that queries Cloud Logging and sends the logs to the SaaS tool.</label>
</div>
</div>
<div class="question">
<p><strong>Question 288:</strong> <strong class="keyword"></strong>

You are planning to migrate a database and a backend application to a Standard Google Kubernetes Engine (GKE) cluster. You need to prevent data loss and make sure there are enough nodes available for your backend application based on the demands of your workloads. You want to follow Google-recommended practices and minimize the amount of manual work required. What should you do?</p>
<div class="answers">
<label><input name="q38" type="radio" value="A"/> A. Run your database as a StatefulSet. Configure cluster autoscaling to handle changes in the demands of your workloads.</label><br/>
<label><input name="q38" type="radio" value="B"/> B. Run your database as a single Pod. Run the resize command when you notice changes in the demands of your workloads.</label><br/>
<label><input name="q38" type="radio" value="C"/> C. Run your database as a DaemonSet. Run the resize command when you notice changes in the demands of your workloads.</label><br/>
<label><input name="q38" type="radio" value="D"/> D. Run your database as a Deployment. Configure cluster autoscaling to handle changes in the demands of your workloads.</label>
</div>
</div>
<div class="question">
<p><strong>Question 289:</strong> <strong class="keyword"></strong>

You are the Organization Administrator for your company's Google Cloud resources. Your company has strict compliance rules that require you to be notified about any modifications to files and documents hosted on Cloud Storage. In a recent incident, one of your team members was able to modify files and you did not receive any notifications, causing other production jobs to fail. You must ensure that you receive notifications for all changes to files and documents in Cloud Storage while minimizing management overhead. What should you do?</p>
<div class="answers">
<label><input name="q39" type="radio" value="A"/> A. View Cloud Audit logs for all Cloud Storage files in Logs Explorer. Filter by Admin Activity logs.</label><br/>
<label><input name="q39" type="radio" value="B"/> B. Enable Cloud Storage object versioning on your bucket. Configure Pub/Sub notifications for your Cloud Storage buckets.</label><br/>
<label><input name="q39" type="radio" value="C"/> C. Enable versioning on the Cloud Storage bucket. Set up a custom script that scans versions of Cloud Storage objects being modified and alert the admin by using the script.</label><br/>
<label><input name="q39" type="radio" value="D"/> D. Configure Object change notifications on the Cloud Storage buckets. Send the events to Pub/Sub.</label>
</div>
</div>
<div class="question">
<p><strong>Question 290:</strong> <strong class="keyword"></strong>

Your company would like to store invoices and other financial documents in Google Cloud. You need to identify a Google-managed solution to store this information for your company. You must ensure that the documents are kept for a duration of three years. Your company‚Äôs analysts need frequent access to invoices from the past six months. After six months, invoices should be archived for audit purposes only. You want to minimize costs and follow Google-recommended practices. What should you do?</p>
<div class="answers">
<label><input name="q40" type="radio" value="A"/> A. Use Cloud Storage with Object Lifecycle Management to change the object storage class to Coldline after six months.</label><br/>
<label><input name="q40" type="radio" value="B"/> B. Use Cloud Storage with Object Lifecycle Management to change the object storage class to Standard after six months.</label><br/>
<label><input name="q40" type="radio" value="C"/> C. Store your documents on Filestore, and move the documents to Cloud Storage with object storage class set to Coldline after six months.</label><br/>
<label><input name="q40" type="radio" value="D"/> D. Store your documents on Filestore, and move the documents to Cloud Storage with object storage class set to Standard after six months.</label>
</div>
</div>
<div class="question">
<p><strong>Question 291:</strong> <strong class="keyword"></strong>

You are planning to migrate your containerized workloads to Google Kubernetes Engine (GKE). You need to determine which GKE option to use. Your solution must have high availability, minimal downtime, and the ability to promptly apply security updates to your nodes. You also want to pay only for the compute resources that your workloads use without managing nodes. You want to follow Google-recommended practices and minimize operational costs. What should you do?</p>
<div class="answers">
<label><input name="q41" type="radio" value="A"/> A. Configure a Standard regional GKE duster.</label><br/>
<label><input name="q41" type="radio" value="B"/> B. Configure a Standard zonal GKE duster.</label><br/>
<label><input name="q41" type="radio" value="C"/> C. Configure a Standard multi-zonal GKE cluster.</label><br/>
<label><input name="q41" type="radio" value="D"/> D. Configure an Autopilot GKE cluster.</label>
</div>
</div>
<div class="question">
<p><strong>Question 292:</strong> <strong class="keyword"></strong>

Your company stores data from multiple sources that have different data storage requirements. These data include:1. Customer data that is structured and read with complex queries2. Historical log data that is large in volume and accessed infrequently3. Real-time sensor data with high-velocity writes, which needs to be available for analysis but can tolerate some data lossYou need to design the most cost-effective storage solution that fulfills all data storage requirements. What should you do?</p>
<div class="answers">
<label><input name="q42" type="radio" value="A"/> A. Use Firestore for customer data, Cloud Storage (Nearline) for historical logs, and Bigtable for sensor data.</label><br/>
<label><input name="q42" type="radio" value="B"/> B. Use Cloud SQL for customer data. Cloud Storage (Coldline) for historical logs, and BigQuery for sensor data.</label><br/>
<label><input name="q42" type="radio" value="C"/> C. Use Cloud SQL for customer data. Cloud Storage (Archive) for historical logs, and Bigtable for sensor data.</label><br/>
<label><input name="q42" type="radio" value="D"/> D. Use Spanner for all data.</label>
</div>
</div>
<div class="question">
<p><strong>Question 293:</strong> <strong class="keyword"></strong>

You work for a financial services company that operates as a stock market broker. Your company is planning to migrate to Google Cloud. You need to plan the network design in Google Cloud. Your design must:‚Ä¢ Minimize the latency between all production systems.‚Ä¢ Minimize costs related to your development environment.What should you do?</p>
<div class="answers">
<label><input name="q43" type="radio" value="A"/> A. Create a VPC in the Standard Tier and one in the Premium Tier. Deploy production workloads in the Standard Tier and development workloads in the Premium Tier.</label><br/>
<label><input name="q43" type="radio" value="B"/> B. Create a VPC in the Standard Tier and one in the Premium Tier. Deploy development workloads in the Standard Tier and production workloads in the Premium Tier.</label><br/>
<label><input name="q43" type="radio" value="C"/> C. Create a VPC in the Premium Tier, and deploy both production and development workloads on this VPC.</label><br/>
<label><input name="q43" type="radio" value="D"/> D. Create a VPC in the Standard Tier, and deploy both production and development workloads on this VPC.</label>
</div>
</div>
<div class="question">
<p><strong>Question 295:</strong> <strong class="keyword"></strong>

Your company was recently impacted by a service disruption that caused multiple Dataflow jobs to get stuck, resulting in significant downtime in downstream applications and revenue loss. You were able to resolve the issue by identifying and fixing an error you found in the code. You need to design a solution with minimal management effort to identify when jobs are stuck in the future to ensure that this issue does not occur again. What should you do?</p>
<div class="answers">
<label><input name="q44" type="radio" value="A"/> A. Update the Dataflow job configurations to send messages to a Pub/Sub topic when there are delays. Configure a backup Dataflow job to process jobs that are delayed. Use Cloud Tasks to trigger an alert when messages are pushed to the Pub/Sub topic.</label><br/>
<label><input name="q44" type="radio" value="B"/> B. Set up Cloud Monitoring alerts on the data freshness metric for the Dataflow jobs to receive a notification when a certain threshold is reached.</label><br/>
<label><input name="q44" type="radio" value="C"/> C. Set up Error Reporting to identify stack traces that indicate slowdowns in Dataflow jobs. Set up alerts based on these log entries.</label><br/>
<label><input name="q44" type="radio" value="D"/> D. Use the Personalized Service Health dashboard to identify issues with Dataflow jobs across regions.</label>
</div>
</div>
<div class="question">
<p><strong>Question 297:</strong> <strong class="keyword"></strong>

You have an application running inside a Compute Engine instance. You want to provide the application with secure access to a BigQuery dataset. You must ensure that credentials are only valid for a short period of time, and your application will only have access to the intended BigQuery dataset. You want to follow Google-recommended practices and minimize your operational costs. What should you do?</p>
<div class="answers">
<label><input name="q45" type="radio" value="A"/> A. Attach a new service account to the instance every hour, and grant the service account the BigQuery Data Viewer IAM role on the project.</label><br/>
<label><input name="q45" type="radio" value="B"/> B. Attach a custom service account to the instance, and grant the service account the BigQuery Data Viewer IAM role on the dataset.</label><br/>
<label><input name="q45" type="radio" value="C"/> C. Attach a new service account to the instance every hour, and grant the service account the BigQuery Data Viewer IAM role on the dataset.</label><br/>
<label><input name="q45" type="radio" value="D"/> D. Attach a custom service account to the instance, and grant the service account the BigQuery Data Viewer IAM role on the project.</label>
</div>
</div>
<div class="question">
<p><strong>Question 300:</strong> <strong class="keyword"></strong>

Your company is seeking a scalable solution to retain and explore application logs hosted on Compute Engine. You must be able to analyze your logs with SQL queries, and you want to be able to create charts to identify patterns and trends in your logs over time. You want to follow Google-recommended practices and minimize your operational costs. What should you do?</p>
<div class="answers">
<label><input name="q46" type="radio" value="A"/> A. Use a custom script to push your application logs to BigQuery for exploration.</label><br/>
<label><input name="q46" type="radio" value="B"/> B. Ingest your application logs to Cloud Logging by using Ops Agent, and explore your logs in Logs Explorer.</label><br/>
<label><input name="q46" type="radio" value="C"/> C. Ingest your application logs to Cloud Logging by using Ops Agent, and explore your logs with Log Analytics.</label><br/>
<label><input name="q46" type="radio" value="D"/> D. Use a custom script to push your application logs to Cloud SQL for exploration.</label>
</div>
</div>
<div class="question">
<p><strong>Question 301:</strong> <strong class="keyword"></strong>

You are deploying an application to Google Kubernetes Engine (GKE). The application needs to make API calls to a private Cloud Storage bucket. You need to configure your application Pods to authenticate to the Cloud Storage API, but your organization policy prevents the usage of service account keys. You want to follow Google-recommended practices. What should you do?</p>
<div class="answers">
<label><input name="q47" type="radio" value="A"/> A. Create the GKE cluster with Workload Identity Federation. Configure the default node service account to access the bucket. Deploy the application into the cluster so the application can use the node service account permissions. Use Identity and Access Management (IAM) to grant the service account access to the bucket.</label><br/>
<label><input name="q47" type="radio" value="B"/> B. Create the GKE cluster with Workload Identity Federation. Create a Google service account and a Kubernetes ServiceAccount, and configure both service accounts to use Workload Identity Federation. Attach the Kubernetes ServiceAccount to the application Pods and configure the Google service account to access the bucket with Identity and Access Management (IAM).</label><br/>
<label><input name="q47" type="radio" value="C"/> C. Create the GKE cluster and deploy the application. Request a security exception to create a Google service account key. Set the constraints/iam.serviceAccountKeyExpiryHours organization policy to 24 hours.</label><br/>
<label><input name="q47" type="radio" value="D"/> D. Create the GKE cluster and deploy the application. Request a security exception to create a Google service account key. Set the constraints/iam.serviceAccountKeyExpiryHours organization policy to 8 hours.</label>
</div>
</div>
<div class="question">
<p><strong>Question 303:</strong> <strong class="keyword"></strong>

You are managing the security configuration of your company‚Äôs Google Cloud organization. The Operations team needs specific permissions on both a Google Kubernetes Engine (GKE) cluster and a Cloud SQL instance. Two predefined Identity and Access Management (IAM) roles exist that contain a subset of the permissions needed by the team. You need to configure the necessary IAM permissions for this team while following Google-recommended practices. What should you do?</p>
<div class="answers">
<label><input name="q48" type="radio" value="A"/> A. Create a custom IAM role that combines the permissions from the two relevant predefined roles.</label><br/>
<label><input name="q48" type="radio" value="B"/> B. Grant the team the two predefined IAM roles.</label><br/>
<label><input name="q48" type="radio" value="C"/> C. Create a custom IAM role that includes only the required permissions from the predefined roles.</label><br/>
<label><input name="q48" type="radio" value="D"/> D. Grant the team the IAM roles of Kubernetes Engine Admin and Cloud SQL Admin.</label>
</div>
</div>
<div class="question">
<p><strong>Question 305:</strong> <strong class="keyword"></strong>

You are planning to deploy an application to Google Cloud. Your application processes asynchronous events from Google services and must be accessible from the public Internet. You need to identify how to deploy your application. You want to follow a standardized process while minimizing development costs. You also want to have no costs when your workloads are not in use. What should you do?</p>
<div class="answers">
<label><input name="q49" type="radio" value="A"/> A. Deploy your code to GKE. Use Pub/Sub for event delivery.</label><br/>
<label><input name="q49" type="radio" value="B"/> B. Deploy your code to Compute Engine. Use Pub/Sub for event delivery.</label><br/>
<label><input name="q49" type="radio" value="C"/> C. Deploy your code to GKE. Use Eventarc for event delivery.</label><br/>
<label><input name="q49" type="radio" value="D"/> D. Deploy your code to Cloud Run. Use Eventarc for event delivery.</label>
</div>
</div>
<div class="question">
<p><strong>Question 311:</strong> <strong class="keyword"></strong>

You need to migrate multiple PostgreSQL databases from your on-premises data center to Google Cloud. You want to significantly improve the performance of your databases while minimizing changes to your data schema and application code. You expect to exceed 150 TB of data per geographical region. You want to follow Google-recommended practices and minimize your operational costs. What should you do?</p>
<div class="answers">
<label><input name="q50" type="radio" value="A"/> A. Migrate your data to AlloyDB.</label><br/>
<label><input name="q50" type="radio" value="B"/> B. Migrate your data to Spanner.</label><br/>
<label><input name="q50" type="radio" value="C"/> C. Migrate your data to Firebase.</label><br/>
<label><input name="q50" type="radio" value="D"/> D. Migrate your data to Bigtable.</label>
</div>
</div>
<div class="question">
<p><strong>Question 312:</strong> <strong class="keyword"></strong>

Your company's machine learning team requires a scalable and flexible platform to fine-tune large language models utilizing a large volume of proprietary data on Google Cloud. You are tasked with building a solution for this team. What should you do?</p>
<div class="answers">
<label><input name="q51" type="radio" value="A"/> A. Use Dataflow as a platform to run the fine-tuning jobs</label><br/>
<label><input name="q51" type="radio" value="B"/> B. Use a Compute Engine managed instance group as a platform to deploy Jupyter Notebooks and run fine-tuning jobs.</label><br/>
<label><input name="q51" type="radio" value="C"/> C. Use Cloud Run and GPU as a platform to run the fine-tuning jobs.</label><br/>
<label><input name="q51" type="radio" value="D"/> D. Use Google Kubernetes Engine (GKE) and hardware accelerators as a platform to run the fine-tuning jobs.</label>
</div>
</div>
<div class="question">
<p><strong>Question 317:</strong> <strong class="keyword"></strong>

You are planning to migrate your on-premises VMs to Google Cloud. You need to set up a landing zone in Google Cloud before migrating the VMs. You must ensure that all VM in your production environment can communicate with each other through private IP addresses. You need to allow all VMs in your Google Cloud organization to accept connections on specific TCP ports. You want to follow Google-recommended practices, and you need to minimize your operational costs. What should you do?</p>
<div class="answers">
<label><input name="q52" type="radio" value="A"/> A. Create individual VPCs per Google Cloud project. Peer all he VPC together. Apply organization policies on the organization level.</label><br/>
<label><input name="q52" type="radio" value="B"/> B. Create individual VPCs for each Google Cloud project. Peer ail ne VPCs together. Apply hierarchical firewall policies on the organization level.</label><br/>
<label><input name="q52" type="radio" value="C"/> C. Create a host VPC project with each production project as its service project. Apply organization policies on the organization level.</label><br/>
<label><input name="q52" type="radio" value="D"/> D. Create a host VPC project with each production project as its service project. Apply hierarchical firewall policies on the organization level.</label>
</div>
</div>
</form>

<script src="../quiz-common.js"></script>
<script>
const correctAnswers = ['D', 'D', 'A', 'C', 'B', 'C', 'B', 'D', 'A', 'A', 'C', 'D', 'A', 'D', 'A', 'B', 'A', 'D', 'C', 'B', 'B', 'D', 'C', 'D', 'A', 'B', 'A', 'A', 'C', 'B', 'C', 'B', 'B', 'C', 'B', 'D', 'B', 'A', 'B', 'A', 'D', 'C', 'B', 'B', 'B', 'C', 'B', 'B', 'D', 'A', 'D', 'D'];

const total = 52;
const partName = 'Part 6 (Questions 251-302)';

// Kh·ªüi t·∫°o quiz khi trang load
document.addEventListener('DOMContentLoaded', function() {
    initializeQuiz(correctAnswers, total, partName, 251);
    
    // X·ª≠ l√Ω n√∫t ƒë√°nh d·∫•u c√¢u kh√≥ ƒë·ªÉ kh√¥ng scroll l√™n ƒë·∫ßu
    const difficultButtons = document.querySelectorAll('.difficult-btn');
    difficultButtons.forEach(function(button) {
        button.addEventListener('click', function(e) {
            e.preventDefault(); // NgƒÉn ch·∫∑n h√†nh vi m·∫∑c ƒë·ªãnh
            e.stopPropagation(); // NgƒÉn ch·∫∑n event bubbling
            
            // L∆∞u v·ªã tr√≠ scroll hi·ªán t·∫°i
            const currentScrollPosition = window.pageYOffset || document.documentElement.scrollTop;
            
            // Th·ª±c hi·ªán toggle ƒë√°nh d·∫•u c√¢u kh√≥
            const questionNumber = this.getAttribute('data-question') || this.textContent.match(/\d+/)?.[0];
            if (questionNumber) {
                toggleDifficultQuestion(questionNumber, partName);
            }
            
            // Kh√¥i ph·ª•c v·ªã tr√≠ scroll
            setTimeout(function() {
                window.scrollTo(0, currentScrollPosition);
            }, 10);
        });
    });
});

// H√†m fallback n·∫øu quiz-common.js kh√¥ng load ƒë∆∞·ª£c
function toggleDifficultQuestion(questionNumber, partName) {
    const button = event.target;
    if (button.classList.contains('marked')) {
        button.classList.remove('marked');
        button.textContent = '‚≠ê ƒê√°nh d·∫•u c√¢u kh√≥';
    } else {
        button.classList.add('marked');
        button.textContent = 'üî• ƒê√£ ƒë√°nh d·∫•u';
    }
}
</script>
</body>
</html>